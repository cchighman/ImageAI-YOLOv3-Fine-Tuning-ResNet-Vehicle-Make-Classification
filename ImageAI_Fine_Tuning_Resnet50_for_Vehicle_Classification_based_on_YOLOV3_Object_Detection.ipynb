{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageAI - Fine Tuning Resnet50 for Vehicle Classification based on YOLOV3 Object Detection ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNi1awHb37FwYjHq66yPn2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cchighman/ImageAI-YOLOv3-Fine-Tuning-Vehicle-Classification/blob/master/ImageAI_Fine_Tuning_Resnet50_for_Vehicle_Classification_based_on_YOLOV3_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdWZtxR3u4Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"cars34.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rja4F5rD2RFB",
        "colab_type": "code",
        "outputId": "11a7d79e-9fa4-46f6-e693-af8f6f1d204e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "!pip install imageai\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageai in /usr/local/lib/python3.6/dist-packages (2.1.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.18.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.2.0)\n",
            "Requirement already satisfied: tensorflow==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVKhBcF7Xyjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"cars65\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lY6RDVgKEn9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNtO8zDE0YfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "from PIL import Image\n",
        "weights_path = \"yolo.h5\"\n",
        "\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath( weights_path)\n",
        "detector.loadModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqpaiDUTor1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r \"cars_out.zip\" \"/content/cars\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIyCuExi0eOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = \"cars/test/prius/\"\n",
        "import copy\n",
        "images = os.listdir(image_path)\n",
        "for image in images:\n",
        "    try:\n",
        "        detections, objects_path = detector.detectObjectsFromImage(input_image=image_path+image, extract_detected_objects=True, output_image_path=\"/content/cars/test/prius/box_\"+image, minimum_percentage_probability = 30)        \n",
        "        for eachObject, eachObjectPath in zip(detections, objects_path):\n",
        "            print(eachObject[\"name\"] , \" : \" , str(eachObject[\"percentage_probability\"]), \" : \", str(eachObject[\"box_points\"]))\n",
        "            for detected in os.listdir(eachObjectPath):\n",
        "                print(\"Copying \" + eachObjecPath + \"/\" + detected + \" to ../\" + detected)\n",
        "                copy.copy(eachObjectPath+\"/\"+detected, \"../\"+detected)\n",
        "\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzSRNp4VzalX",
        "colab_type": "code",
        "outputId": "add99b2f-f78a-457c-ded6-4327f339ab8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from imageai.Prediction.Custom import ModelTraining\n",
        "model_trainer = ModelTraining()\n",
        "model_trainer.setModelTypeAsResNet()\n",
        "model_trainer.setDataDirectory(\"/content/cars\")\n",
        "model_trainer.trainModel(num_objects=2, num_experiments=100, save_full_model=True, transfer_with_full_training=True, transfer_from_model=\"resnet50_weights_tf_dim_ordering_tf_kernels.h5\", enhance_data=True, batch_size=32, show_network_summary=True)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with all layers of the Model\n",
            "Training using weights from a pre-trained model\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 112, 112, 64) 9472        input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 112, 112, 64) 256         conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 112, 112, 64) 0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_456[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 55, 55, 64)   4160        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 55, 55, 64)   256         conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 55, 55, 64)   0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 55, 55, 64)   36928       activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 55, 55, 64)   256         conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 55, 55, 64)   0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 55, 55, 256)  16640       activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 55, 55, 256)  16640       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 55, 55, 256)  1024        conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 55, 55, 256)  1024        conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_144 (Add)                   (None, 55, 55, 256)  0           batch_normalization_481[0][0]    \n",
            "                                                                 batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 55, 55, 256)  0           add_144[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 55, 55, 64)   16448       activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 55, 55, 64)   256         conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 55, 55, 64)   0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 55, 55, 64)   36928       activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 55, 55, 64)   256         conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 55, 55, 64)   0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 55, 55, 256)  16640       activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 55, 55, 256)  1024        conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_145 (Add)                   (None, 55, 55, 256)  0           batch_normalization_484[0][0]    \n",
            "                                                                 activation_459[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 55, 55, 256)  0           add_145[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 55, 55, 64)   16448       activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 55, 55, 64)   256         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 55, 55, 64)   0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 55, 55, 64)   36928       activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 55, 55, 64)   256         conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 55, 55, 64)   0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 55, 55, 256)  16640       activation_464[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 55, 55, 256)  1024        conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_146 (Add)                   (None, 55, 55, 256)  0           batch_normalization_487[0][0]    \n",
            "                                                                 activation_462[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 55, 55, 256)  0           add_146[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 28, 28, 128)  32896       activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 28, 28, 128)  512         conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 28, 28, 128)  0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 28, 28, 128)  147584      activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 28, 28, 128)  512         conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 28, 28, 128)  0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 28, 28, 512)  66048       activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 28, 28, 512)  131584      activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 28, 28, 512)  2048        conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 28, 28, 512)  2048        conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_147 (Add)                   (None, 28, 28, 512)  0           batch_normalization_491[0][0]    \n",
            "                                                                 batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 28, 28, 512)  0           add_147[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 28, 28, 128)  65664       activation_468[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 28, 28, 128)  512         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 28, 28, 128)  0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 28, 28, 128)  147584      activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 28, 28, 128)  512         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 28, 28, 128)  0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 28, 28, 512)  66048       activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 28, 28, 512)  2048        conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_148 (Add)                   (None, 28, 28, 512)  0           batch_normalization_494[0][0]    \n",
            "                                                                 activation_468[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 28, 28, 512)  0           add_148[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 28, 28, 128)  65664       activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 28, 28, 128)  512         conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 28, 28, 128)  0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 28, 28, 128)  147584      activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 28, 28, 128)  512         conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 28, 28, 128)  0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 28, 28, 512)  66048       activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, 28, 28, 512)  2048        conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_149 (Add)                   (None, 28, 28, 512)  0           batch_normalization_497[0][0]    \n",
            "                                                                 activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 28, 28, 512)  0           add_149[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 28, 28, 128)  65664       activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, 28, 28, 128)  512         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 28, 28, 128)  0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 28, 28, 128)  147584      activation_475[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, 28, 28, 128)  512         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 28, 28, 128)  0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 28, 28, 512)  66048       activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, 28, 28, 512)  2048        conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_150 (Add)                   (None, 28, 28, 512)  0           batch_normalization_500[0][0]    \n",
            "                                                                 activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 28, 28, 512)  0           add_150[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 14, 14, 256)  131328      activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, 14, 14, 256)  1024        conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 14, 14, 256)  0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 14, 14, 256)  590080      activation_478[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, 14, 14, 256)  1024        conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 14, 14, 256)  0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 14, 14, 1024) 263168      activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 14, 14, 1024) 525312      activation_477[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, 14, 14, 1024) 4096        conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, 14, 14, 1024) 4096        conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_151 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_504[0][0]    \n",
            "                                                                 batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 14, 14, 1024) 0           add_151[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 14, 14, 256)  262400      activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, 14, 14, 256)  1024        conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 14, 14, 256)  0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 14, 14, 256)  590080      activation_481[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, 14, 14, 256)  1024        conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 14, 14, 256)  0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 14, 14, 1024) 263168      activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, 14, 14, 1024) 4096        conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_152 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_507[0][0]    \n",
            "                                                                 activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 14, 14, 1024) 0           add_152[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 14, 14, 256)  262400      activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, 14, 14, 256)  1024        conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 14, 14, 256)  0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 14, 14, 256)  590080      activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, 14, 14, 256)  1024        conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 14, 14, 256)  0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 14, 14, 1024) 263168      activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, 14, 14, 1024) 4096        conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_153 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_510[0][0]    \n",
            "                                                                 activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 14, 14, 1024) 0           add_153[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 14, 14, 256)  262400      activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, 14, 14, 256)  1024        conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 14, 14, 256)  0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 14, 14, 256)  590080      activation_487[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, 14, 14, 256)  1024        conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 14, 14, 256)  0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 14, 14, 1024) 263168      activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, 14, 14, 1024) 4096        conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_154 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_513[0][0]    \n",
            "                                                                 activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 14, 14, 1024) 0           add_154[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 14, 14, 256)  262400      activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, 14, 14, 256)  1024        conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 14, 14, 256)  0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 14, 14, 256)  590080      activation_490[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, 14, 14, 256)  1024        conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 14, 14, 256)  0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 14, 14, 1024) 263168      activation_491[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, 14, 14, 1024) 4096        conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_155 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_516[0][0]    \n",
            "                                                                 activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 14, 14, 1024) 0           add_155[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 14, 14, 256)  262400      activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, 14, 14, 256)  1024        conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 14, 14, 256)  0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 14, 14, 256)  590080      activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, 14, 14, 256)  1024        conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 14, 14, 256)  0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 14, 14, 1024) 263168      activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, 14, 14, 1024) 4096        conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_156 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_519[0][0]    \n",
            "                                                                 activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 14, 14, 1024) 0           add_156[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 7, 7, 512)    524800      activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, 7, 7, 512)    2048        conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 7, 7, 512)    0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 7, 7, 512)    2359808     activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, 7, 7, 512)    2048        conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 7, 7, 512)    0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 7, 7, 2048)   8192        conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, 7, 7, 2048)   8192        conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_157 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_523[0][0]    \n",
            "                                                                 batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 7, 7, 2048)   0           add_157[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 7, 7, 512)    1049088     activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 7, 7, 512)    2048        conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 7, 7, 512)    0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 7, 7, 512)    2359808     activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 7, 7, 512)    2048        conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 7, 7, 512)    0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 7, 7, 2048)   8192        conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_158 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_526[0][0]    \n",
            "                                                                 activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 7, 7, 2048)   0           add_158[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 7, 7, 512)    1049088     activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 7, 7, 512)    2048        conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 7, 7, 512)    0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 7, 7, 512)    2359808     activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, 7, 7, 512)    2048        conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 7, 7, 512)    0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_503[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, 7, 7, 2048)   8192        conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_159 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_529[0][0]    \n",
            "                                                                 activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 7, 7, 2048)   0           add_159[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_avg_pooling (GlobalAvera (None, 2048)         0           activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 2)            4098        global_avg_pooling[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 2)            0           dense_16[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 23,538,690\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
            "Using Enhanced Data Generation\n",
            "Found 3100 images belonging to 2 classes.\n",
            "Found 2176 images belonging to 2 classes.\n",
            "JSON Mapping for the model classes saved to  /content/cars/json/model_class.json\n",
            "Number of experiments (Epochs) :  100\n",
            "Epoch 1/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.3924 - acc: 0.8834Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 6s - loss: 0.3533 - acc: 0.8888\n",
            "Epoch 00001: val_acc improved from -inf to 0.88879, saving model to /content/cars/models/model_ex-001_acc-0.888787.h5\n",
            "96/96 [==============================] - 398s 4s/step - loss: 0.3903 - acc: 0.8843 - val_loss: 0.3533 - val_acc: 0.8888\n",
            "Epoch 2/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9269Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.4713 - acc: 0.8888\n",
            "Epoch 00002: val_acc did not improve from 0.88879\n",
            "96/96 [==============================] - 52s 537ms/step - loss: 0.1781 - acc: 0.9276 - val_loss: 0.4713 - val_acc: 0.8888\n",
            "Epoch 3/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9496Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3783 - acc: 0.8888\n",
            "Epoch 00003: val_acc did not improve from 0.88879\n",
            "96/96 [==============================] - 52s 538ms/step - loss: 0.1394 - acc: 0.9498 - val_loss: 0.3783 - val_acc: 0.8888\n",
            "Epoch 4/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9697Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3507 - acc: 0.8888\n",
            "Epoch 00004: val_acc did not improve from 0.88879\n",
            "96/96 [==============================] - 52s 538ms/step - loss: 0.0879 - acc: 0.9700 - val_loss: 0.3507 - val_acc: 0.8888\n",
            "Epoch 5/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9694Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3737 - acc: 0.8888\n",
            "Epoch 00005: val_acc did not improve from 0.88879\n",
            "96/96 [==============================] - 51s 533ms/step - loss: 0.0892 - acc: 0.9697 - val_loss: 0.3737 - val_acc: 0.8888\n",
            "Epoch 6/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9822Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3600 - acc: 0.8888\n",
            "Epoch 00006: val_acc did not improve from 0.88879\n",
            "96/96 [==============================] - 51s 526ms/step - loss: 0.0481 - acc: 0.9821 - val_loss: 0.3600 - val_acc: 0.8888\n",
            "Epoch 7/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9865Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.2909 - acc: 0.9306\n",
            "Epoch 00007: val_acc improved from 0.88879 to 0.93061, saving model to /content/cars/models/model_ex-007_acc-0.930607.h5\n",
            "96/96 [==============================] - 51s 533ms/step - loss: 0.0419 - acc: 0.9863 - val_loss: 0.2909 - val_acc: 0.9306\n",
            "Epoch 8/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9918Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.1608 - acc: 0.9334\n",
            "Epoch 00008: val_acc improved from 0.93061 to 0.93336, saving model to /content/cars/models/model_ex-008_acc-0.933364.h5\n",
            "96/96 [==============================] - 51s 529ms/step - loss: 0.0239 - acc: 0.9919 - val_loss: 0.1608 - val_acc: 0.9334\n",
            "Epoch 9/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9743Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 10.8524 - acc: 0.1131\n",
            "Epoch 00009: val_acc did not improve from 0.93336\n",
            "96/96 [==============================] - 48s 500ms/step - loss: 0.0729 - acc: 0.9739 - val_loss: 10.8524 - val_acc: 0.1131\n",
            "Epoch 10/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9862Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0470 - acc: 0.9862\n",
            "Epoch 00010: val_acc improved from 0.93336 to 0.98621, saving model to /content/cars/models/model_ex-010_acc-0.986213.h5\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0323 - acc: 0.9863 - val_loss: 0.0470 - val_acc: 0.9862\n",
            "Epoch 11/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9862Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.1303 - acc: 0.9522\n",
            "Epoch 00011: val_acc did not improve from 0.98621\n",
            "96/96 [==============================] - 48s 503ms/step - loss: 0.0394 - acc: 0.9863 - val_loss: 0.1303 - val_acc: 0.9522\n",
            "Epoch 12/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9904Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 5.3862 - acc: 0.8888\n",
            "Epoch 00012: val_acc did not improve from 0.98621\n",
            "96/96 [==============================] - 48s 496ms/step - loss: 0.0280 - acc: 0.9902 - val_loss: 5.3862 - val_acc: 0.8888\n",
            "Epoch 13/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9799Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.4894 - acc: 0.8028\n",
            "Epoch 00013: val_acc did not improve from 0.98621\n",
            "96/96 [==============================] - 48s 496ms/step - loss: 0.0500 - acc: 0.9801 - val_loss: 0.4894 - val_acc: 0.8028\n",
            "Epoch 14/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9852Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3979 - acc: 0.9145\n",
            "Epoch 00014: val_acc did not improve from 0.98621\n",
            "96/96 [==============================] - 48s 500ms/step - loss: 0.0482 - acc: 0.9853 - val_loss: 0.3979 - val_acc: 0.9145\n",
            "Epoch 15/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9914Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0531 - acc: 0.9899\n",
            "Epoch 00015: val_acc improved from 0.98621 to 0.98989, saving model to /content/cars/models/model_ex-015_acc-0.989890.h5\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.0531 - val_acc: 0.9899\n",
            "Epoch 16/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9891Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.1236 - acc: 0.9508\n",
            "Epoch 00016: val_acc did not improve from 0.98989\n",
            "96/96 [==============================] - 47s 494ms/step - loss: 0.0339 - acc: 0.9892 - val_loss: 0.1236 - val_acc: 0.9508\n",
            "Epoch 17/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9967Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0216 - acc: 0.9913\n",
            "Epoch 00017: val_acc improved from 0.98989 to 0.99127, saving model to /content/cars/models/model_ex-017_acc-0.991268.h5\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0216 - val_acc: 0.9913\n",
            "Epoch 18/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9954Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0411 - acc: 0.9825\n",
            "Epoch 00018: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 47s 489ms/step - loss: 0.0149 - acc: 0.9954 - val_loss: 0.0411 - val_acc: 0.9825\n",
            "Epoch 19/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9792Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0570 - acc: 0.9798\n",
            "Epoch 00019: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 47s 486ms/step - loss: 0.0516 - acc: 0.9795 - val_loss: 0.0570 - val_acc: 0.9798\n",
            "Epoch 20/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9888Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.3950 - acc: 0.8208\n",
            "Epoch 00020: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 47s 491ms/step - loss: 0.0328 - acc: 0.9889 - val_loss: 0.3950 - val_acc: 0.8208\n",
            "Epoch 21/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9931Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 1.1778 - acc: 0.8929\n",
            "Epoch 00021: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 47s 486ms/step - loss: 0.0244 - acc: 0.9932 - val_loss: 1.1778 - val_acc: 0.8929\n",
            "Epoch 22/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9937Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0405 - acc: 0.9894\n",
            "Epoch 00022: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 46s 483ms/step - loss: 0.0174 - acc: 0.9935 - val_loss: 0.0405 - val_acc: 0.9894\n",
            "Epoch 23/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9964Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 6.3710 - acc: 0.1351\n",
            "Epoch 00023: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 46s 482ms/step - loss: 0.0174 - acc: 0.9964 - val_loss: 6.3710 - val_acc: 0.1351\n",
            "Epoch 24/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9908Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.2527 - acc: 0.9591\n",
            "Epoch 00024: val_acc did not improve from 0.99127\n",
            "96/96 [==============================] - 46s 480ms/step - loss: 0.0225 - acc: 0.9909 - val_loss: 0.2527 - val_acc: 0.9591\n",
            "Epoch 25/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9954Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0237 - acc: 0.9926\n",
            "Epoch 00025: val_acc improved from 0.99127 to 0.99265, saving model to /content/cars/models/model_ex-025_acc-0.992647.h5\n",
            "96/96 [==============================] - 48s 498ms/step - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0237 - val_acc: 0.9926\n",
            "Epoch 26/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9951Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.8543 - acc: 0.9021\n",
            "Epoch 00026: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 47s 487ms/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.8543 - val_acc: 0.9021\n",
            "Epoch 27/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9904Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.1393 - acc: 0.9540\n",
            "Epoch 00027: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 46s 481ms/step - loss: 0.0284 - acc: 0.9902 - val_loss: 0.1393 - val_acc: 0.9540\n",
            "Epoch 28/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9924Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 1.6713 - acc: 0.8888\n",
            "Epoch 00028: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 45s 473ms/step - loss: 0.0204 - acc: 0.9925 - val_loss: 1.6713 - val_acc: 0.8888\n",
            "Epoch 29/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9819Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.2763 - acc: 0.9090\n",
            "Epoch 00029: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 45s 471ms/step - loss: 0.0498 - acc: 0.9821 - val_loss: 0.2763 - val_acc: 0.9090\n",
            "Epoch 30/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9855Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0459 - acc: 0.9848\n",
            "Epoch 00030: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 45s 472ms/step - loss: 0.0427 - acc: 0.9853 - val_loss: 0.0459 - val_acc: 0.9848\n",
            "Epoch 31/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9944Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0308 - acc: 0.9885\n",
            "Epoch 00031: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 45s 473ms/step - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0308 - val_acc: 0.9885\n",
            "Epoch 32/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9967Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0393 - acc: 0.9848\n",
            "Epoch 00032: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 46s 474ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0393 - val_acc: 0.9848\n",
            "Epoch 33/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9901Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.7363 - acc: 0.9035\n",
            "Epoch 00033: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 46s 477ms/step - loss: 0.0272 - acc: 0.9902 - val_loss: 0.7363 - val_acc: 0.9035\n",
            "Epoch 34/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9921Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.1590 - acc: 0.9504\n",
            "Epoch 00034: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 46s 478ms/step - loss: 0.0215 - acc: 0.9922 - val_loss: 0.1590 - val_acc: 0.9504\n",
            "Epoch 35/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9924Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0402 - acc: 0.9871\n",
            "Epoch 00035: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 46s 477ms/step - loss: 0.0197 - acc: 0.9925 - val_loss: 0.0402 - val_acc: 0.9871\n",
            "Epoch 36/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9970Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0479 - acc: 0.9913\n",
            "Epoch 00036: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 49s 510ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0479 - val_acc: 0.9913\n",
            "Epoch 37/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9980Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0696 - acc: 0.9825\n",
            "Epoch 00037: val_acc did not improve from 0.99265\n",
            "96/96 [==============================] - 50s 526ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0696 - val_acc: 0.9825\n",
            "Epoch 38/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9970Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0159 - acc: 0.9940\n",
            "Epoch 00038: val_acc improved from 0.99265 to 0.99403, saving model to /content/cars/models/model_ex-038_acc-0.994026.h5\n",
            "96/96 [==============================] - 51s 534ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0159 - val_acc: 0.9940\n",
            "Epoch 39/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9931Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0658 - acc: 0.9724\n",
            "Epoch 00039: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 509ms/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0658 - val_acc: 0.9724\n",
            "Epoch 40/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9941Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0384 - acc: 0.9922\n",
            "Epoch 00040: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 513ms/step - loss: 0.0151 - acc: 0.9938 - val_loss: 0.0384 - val_acc: 0.9922\n",
            "Epoch 41/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9951Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.6658 - acc: 0.8153\n",
            "Epoch 00041: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 503ms/step - loss: 0.0106 - acc: 0.9951 - val_loss: 0.6658 - val_acc: 0.8153\n",
            "Epoch 42/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9980Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0577 - acc: 0.9839\n",
            "Epoch 00042: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 504ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0577 - val_acc: 0.9839\n",
            "Epoch 43/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9987Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0317 - acc: 0.9917\n",
            "Epoch 00043: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 502ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 0.0317 - val_acc: 0.9917\n",
            "Epoch 44/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9993Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0306 - acc: 0.9922\n",
            "Epoch 00044: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 504ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0306 - val_acc: 0.9922\n",
            "Epoch 45/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0363 - acc: 0.9894\n",
            "Epoch 00045: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 502ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9894\n",
            "Epoch 46/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0321 - acc: 0.9913\n",
            "Epoch 00046: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9913\n",
            "Epoch 47/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0297 - acc: 0.9926\n",
            "Epoch 00047: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 529ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0297 - val_acc: 0.9926\n",
            "Epoch 48/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9990Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0191 - acc: 0.9936\n",
            "Epoch 00048: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 521ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0191 - val_acc: 0.9936\n",
            "Epoch 49/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0331 - acc: 0.9903\n",
            "Epoch 00049: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 528ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0331 - val_acc: 0.9903\n",
            "Epoch 50/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9990Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0402 - acc: 0.9890\n",
            "Epoch 00050: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 538ms/step - loss: 0.0016 - acc: 0.9990 - val_loss: 0.0402 - val_acc: 0.9890\n",
            "Epoch 51/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 8.7717e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0297 - acc: 0.9926\n",
            "Epoch 00051: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 544ms/step - loss: 8.9723e-04 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9926\n",
            "Epoch 52/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0246 - acc: 0.9931\n",
            "Epoch 00052: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 534ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9931\n",
            "Epoch 53/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0398 - acc: 0.9890\n",
            "Epoch 00053: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 520ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0398 - val_acc: 0.9890\n",
            "Epoch 54/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.5834e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0283 - acc: 0.9936\n",
            "Epoch 00054: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 3.5753e-04 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9936\n",
            "Epoch 55/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 9.8195e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0224 - acc: 0.9940\n",
            "Epoch 00055: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 9.7313e-04 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 0.9940\n",
            "Epoch 56/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.7127e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0266 - acc: 0.9926\n",
            "Epoch 00056: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 5.7572e-04 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9926\n",
            "Epoch 57/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 5.6123e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0256 - acc: 0.9931\n",
            "Epoch 00057: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 512ms/step - loss: 5.5683e-04 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9931\n",
            "Epoch 58/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.2655e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0282 - acc: 0.9931\n",
            "Epoch 00058: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 511ms/step - loss: 3.2535e-04 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9931\n",
            "Epoch 59/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.2464e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0297 - acc: 0.9931\n",
            "Epoch 00059: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 505ms/step - loss: 4.2214e-04 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9931\n",
            "Epoch 60/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.3764e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0316 - acc: 0.9917\n",
            "Epoch 00060: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 504ms/step - loss: 4.3318e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9917\n",
            "Epoch 61/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.0595e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0364 - acc: 0.9917\n",
            "Epoch 00061: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 501ms/step - loss: 4.0187e-04 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 0.9917\n",
            "Epoch 62/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0372 - acc: 0.9913\n",
            "Epoch 00062: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 503ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0372 - val_acc: 0.9913\n",
            "Epoch 63/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.6352e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0362 - acc: 0.9917\n",
            "Epoch 00063: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 504ms/step - loss: 3.6200e-04 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9917\n",
            "Epoch 64/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.3145e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0345 - acc: 0.9922\n",
            "Epoch 00064: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 507ms/step - loss: 3.2815e-04 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 0.9922\n",
            "Epoch 65/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 6.9661e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0335 - acc: 0.9926\n",
            "Epoch 00065: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 495ms/step - loss: 6.8952e-04 - acc: 0.9997 - val_loss: 0.0335 - val_acc: 0.9926\n",
            "Epoch 66/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0299 - acc: 0.9926\n",
            "Epoch 00066: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 500ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0299 - val_acc: 0.9926\n",
            "Epoch 67/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.3173e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0308 - acc: 0.9926\n",
            "Epoch 00067: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 501ms/step - loss: 4.2788e-04 - acc: 0.9997 - val_loss: 0.0308 - val_acc: 0.9926\n",
            "Epoch 68/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 6.8871e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0304 - acc: 0.9926\n",
            "Epoch 00068: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 502ms/step - loss: 6.8156e-04 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9926\n",
            "Epoch 69/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.1277e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0310 - acc: 0.9926\n",
            "Epoch 00069: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 499ms/step - loss: 2.1097e-04 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9926\n",
            "Epoch 70/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 7.3278e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0321 - acc: 0.9926\n",
            "Epoch 00070: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 506ms/step - loss: 7.2553e-04 - acc: 0.9997 - val_loss: 0.0321 - val_acc: 0.9926\n",
            "Epoch 71/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 6.9974e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0303 - acc: 0.9926\n",
            "Epoch 00071: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 505ms/step - loss: 7.0214e-04 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9926\n",
            "Epoch 72/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.1585e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0307 - acc: 0.9926\n",
            "Epoch 00072: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 499ms/step - loss: 3.1260e-04 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9926\n",
            "Epoch 73/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.4950e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0319 - acc: 0.9926\n",
            "Epoch 00073: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 508ms/step - loss: 4.4505e-04 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9926\n",
            "Epoch 74/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.0933e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0307 - acc: 0.9926\n",
            "Epoch 00074: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 521ms/step - loss: 3.0704e-04 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9926\n",
            "Epoch 75/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.0323e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0314 - acc: 0.9926\n",
            "Epoch 00075: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 528ms/step - loss: 2.0409e-04 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9926\n",
            "Epoch 76/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 9.6314e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0305 - acc: 0.9926\n",
            "Epoch 00076: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 530ms/step - loss: 9.5443e-04 - acc: 0.9997 - val_loss: 0.0305 - val_acc: 0.9926\n",
            "Epoch 77/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.4115e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0308 - acc: 0.9926\n",
            "Epoch 00077: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 530ms/step - loss: 1.3977e-04 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9926\n",
            "Epoch 78/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.4479e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0300 - acc: 0.9922\n",
            "Epoch 00078: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 530ms/step - loss: 4.4136e-04 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 0.9922\n",
            "Epoch 79/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.9664e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0303 - acc: 0.9922\n",
            "Epoch 00079: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 537ms/step - loss: 2.9364e-04 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 0.9922\n",
            "Epoch 80/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.8936e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0315 - acc: 0.9922\n",
            "Epoch 00080: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 537ms/step - loss: 3.0074e-04 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9922\n",
            "Epoch 81/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.6739e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0316 - acc: 0.9922\n",
            "Epoch 00081: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 537ms/step - loss: 4.6292e-04 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9922\n",
            "Epoch 82/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 8.9889e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0311 - acc: 0.9922\n",
            "Epoch 00082: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 543ms/step - loss: 8.9025e-04 - acc: 0.9997 - val_loss: 0.0311 - val_acc: 0.9922\n",
            "Epoch 83/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.9726e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0307 - acc: 0.9922\n",
            "Epoch 00083: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 530ms/step - loss: 4.4683e-04 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "Epoch 84/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 7.0316e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0302 - acc: 0.9922\n",
            "Epoch 00084: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 525ms/step - loss: 6.9601e-04 - acc: 0.9997 - val_loss: 0.0302 - val_acc: 0.9922\n",
            "Epoch 85/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.5140e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0321 - acc: 0.9917\n",
            "Epoch 00085: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 529ms/step - loss: 1.5052e-04 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9917\n",
            "Epoch 86/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.5211e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0307 - acc: 0.9922\n",
            "Epoch 00086: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 52s 544ms/step - loss: 2.6113e-04 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "Epoch 87/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.8675e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0321 - acc: 0.9917\n",
            "Epoch 00087: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 535ms/step - loss: 2.8471e-04 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9917\n",
            "Epoch 88/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0320 - acc: 0.9917\n",
            "Epoch 00088: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 528ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0320 - val_acc: 0.9917\n",
            "Epoch 89/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 5.8576e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0309 - acc: 0.9922\n",
            "Epoch 00089: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 529ms/step - loss: 5.7972e-04 - acc: 0.9997 - val_loss: 0.0309 - val_acc: 0.9922\n",
            "Epoch 90/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.6121e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0314 - acc: 0.9922\n",
            "Epoch 00090: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 533ms/step - loss: 2.5884e-04 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9922\n",
            "Epoch 91/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 7.9580e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0310 - acc: 0.9922\n",
            "Epoch 00091: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 527ms/step - loss: 7.8759e-04 - acc: 0.9997 - val_loss: 0.0310 - val_acc: 0.9922\n",
            "Epoch 92/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 3.6623e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0308 - acc: 0.9922\n",
            "Epoch 00092: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 526ms/step - loss: 3.6247e-04 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9922\n",
            "Epoch 93/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 1.9335e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0319 - acc: 0.9917\n",
            "Epoch 00093: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 523ms/step - loss: 1.9147e-04 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9917\n",
            "Epoch 94/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.3362e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0309 - acc: 0.9922\n",
            "Epoch 00094: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 526ms/step - loss: 2.3710e-04 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9922\n",
            "Epoch 95/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 2.4488e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0315 - acc: 0.9922\n",
            "Epoch 00095: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 50s 519ms/step - loss: 2.4279e-04 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9922\n",
            "Epoch 96/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 7.7128e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0319 - acc: 0.9917\n",
            "Epoch 00096: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 526ms/step - loss: 7.7671e-04 - acc: 0.9997 - val_loss: 0.0319 - val_acc: 0.9917\n",
            "Epoch 97/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 8.7461e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0312 - acc: 0.9922\n",
            "Epoch 00097: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 49s 514ms/step - loss: 8.7415e-04 - acc: 0.9997 - val_loss: 0.0312 - val_acc: 0.9922\n",
            "Epoch 98/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 7.1305e-04 - acc: 0.9997Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0318 - acc: 0.9917\n",
            "Epoch 00098: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 48s 495ms/step - loss: 7.0587e-04 - acc: 0.9997 - val_loss: 0.0318 - val_acc: 0.9917\n",
            "Epoch 99/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 8.8943e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0312 - acc: 0.9922\n",
            "Epoch 00099: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 534ms/step - loss: 8.8046e-04 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 0.9922\n",
            "Epoch 100/100\n",
            "95/96 [============================>.] - ETA: 0s - loss: 6.5087e-04 - acc: 1.0000Epoch 1/100\n",
            "68/96 [====================>.........] - ETA: 3s - loss: 0.0317 - acc: 0.9917\n",
            "Epoch 00100: val_acc did not improve from 0.99403\n",
            "96/96 [==============================] - 51s 531ms/step - loss: 6.4421e-04 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njQcjPG0dpLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r cars_trained cars/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZKKOh2nSggv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozUAGiaLSn34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_IVkMS4WGPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf1j3mcxWgHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install httplib2==0.15.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qikCMdZKXPD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -cvzf model.tgz /content/cars/models/model_ex-093_acc-0.818203.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4sf8r5SSvpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "file5 = drive.CreateFile()\n",
        "# Read file and set it as a content of this instance.\n",
        "file5.SetContentFile('/content/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "file5.Upload() # Upload the file."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv_LObCPwLiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Prediction.Custom import CustomImagePrediction\n",
        "prediction = CustomImagePrediction()\n",
        "prediction.setModelTypeAsResNet()\n",
        "prediction.setModelPath( \"/content/cars/models/model_ex-038_acc-0.994026.h5\")\n",
        "prediction.setJsonPath( \"/content/cars/json/model_class.json\")\n",
        "prediction.loadModel(num_objects=191)\n",
        "\n",
        "predictions, probabilities = prediction.predictImage(\"/content/cars/train/prius/00808_8eU6U08ZMn7_600x450.jpg\", result_count=5)\n",
        "for eachPrediction, eachProbability in zip(predictions, probabilities):\n",
        "\tprint(eachPrediction, \" : \", eachProbability)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}